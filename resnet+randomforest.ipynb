{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 6s/step\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 12s/step\n",
      "Validation Accuracy: 0.4107142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.47      0.43        58\n",
      "           1       0.15      0.09      0.11        76\n",
      "           2       0.37      0.36      0.36       146\n",
      "           3       0.51      0.57      0.54       187\n",
      "           4       0.37      0.41      0.38        37\n",
      "\n",
      "    accuracy                           0.41       504\n",
      "   macro avg       0.36      0.38      0.37       504\n",
      "weighted avg       0.39      0.41      0.40       504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data_from_folder(folder_path, target_size=(256, 256)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for subdir in os.listdir(folder_path):\n",
    "        subdir_path = os.path.join(folder_path, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            for filename in os.listdir(subdir_path):\n",
    "                img_path = os.path.join(subdir_path, filename)\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    image = load_img(img_path, target_size=target_size)\n",
    "                    image = img_to_array(image) / 255.0  # Normalize to [0, 1]\n",
    "                    images.append(image)\n",
    "                    labels.append(subdir)  # Use subdirectory name as label\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Extract features using ResNet50\n",
    "def extract_resnet50_features(images):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "    features = base_model.predict(images)\n",
    "    return features.reshape((features.shape[0], -1))  # Flatten features\n",
    "\n",
    "# Handcrafted features (edge detection, texture, etc.)\n",
    "def extract_handcrafted_features(images):\n",
    "    feature_list = []\n",
    "    for img in images:\n",
    "        gray = cv2.cvtColor((img * 255).astype('uint8'), cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Edge detection (Canny)\n",
    "        edges = cv2.Canny(gray, 100, 200)\n",
    "        \n",
    "        # Texture detection (Laplacian)\n",
    "        laplacian = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        \n",
    "        # Hough Line detection\n",
    "        lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)\n",
    "        num_lines = len(lines) if lines is not None else 0\n",
    "        \n",
    "        # Combine handcrafted features\n",
    "        handcrafted_features = [laplacian, num_lines]\n",
    "        feature_list.append(handcrafted_features)\n",
    "    return np.array(feature_list)\n",
    "\n",
    "# Function to balance the dataset using SMOTE\n",
    "def balance_dataset(X, y):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "# Load train data\n",
    "train_data_path = r\"C:\\Users\\ganga\\Documents\\IISc Coursework\\ML4CPS\\Project1\\Project 1 Data\\Project 1 Data\\Train_Data\"\n",
    "train_images, train_labels = load_data_from_folder(train_data_path)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_images_split, val_images_split, train_labels_split, val_labels_split = train_test_split(\n",
    "    train_images, train_labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Extract ResNet50 features\n",
    "resnet50_train_features = extract_resnet50_features(train_images_split)\n",
    "resnet50_val_features = extract_resnet50_features(val_images_split)\n",
    "\n",
    "# Extract handcrafted features (e.g., edges, lines)\n",
    "handcrafted_train_features = extract_handcrafted_features(train_images_split)\n",
    "handcrafted_val_features = extract_handcrafted_features(val_images_split)\n",
    "\n",
    "# Combine features (ResNet50 + handcrafted)\n",
    "X_train_combined = np.hstack([resnet50_train_features, handcrafted_train_features])\n",
    "X_val_combined = np.hstack([resnet50_val_features, handcrafted_val_features])\n",
    "\n",
    "# Balance the dataset using SMOTE\n",
    "X_train_resampled, y_train_resampled = balance_dataset(X_train_combined, train_labels_split)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on validation data\n",
    "val_predictions = rf.predict(X_val_combined)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Validation Accuracy: {accuracy_score(val_labels_split, val_predictions)}')\n",
    "print(classification_report(val_labels_split, val_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 478 images.\n"
     ]
    }
   ],
   "source": [
    "test_dir = r\"C:\\Users\\ganga\\Documents\\IISc Coursework\\ML4CPS\\Project1\\Project 1 Data\\Project 1 Data\\Test_Data\"\n",
    "\n",
    "def load_test_data(test_dir):\n",
    "    test_images = []\n",
    "    test_ids = []\n",
    "    for img_name in os.listdir(test_dir):\n",
    "        img_path = os.path.join(test_dir, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            test_images.append(img)\n",
    "            test_ids.append(img_name.split('.')[0])\n",
    "\n",
    "    print(f\"Loaded {len(test_images)} images.\")\n",
    "\n",
    "    return np.array(test_images), test_ids\n",
    "\n",
    "# Load test data\n",
    "test_images, test_ids = load_test_data(test_dir)\n",
    "\n",
    "# Normalize test data\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "#Test data feature extraction\n",
    "# Extract ResNet50 features\n",
    "resnet50_test_features = extract_resnet50_features(test_images)\n",
    "\n",
    "# Extract handcrafted features (e.g., edges, lines)\n",
    "handcrafted_test_features = extract_handcrafted_features(test_images)\n",
    "\n",
    "# Combine features (ResNet50 + handcrafted)\n",
    "X_test_combined = np.hstack([resnet50_test_features, handcrafted_test_features])\n",
    "\n",
    "# Predict on test data\n",
    "test_predictions = rf.predict(X_test_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created successfully.\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = test_predictions + 1  # Adjust to match original labels\n",
    "\n",
    "# Ensure predicted_classes has 478 entries\n",
    "if len(predicted_classes) < 478:\n",
    "    print(f\"Expected 478 images, but loaded {len(test_ids)}. Adding placeholder rows for missing images.\")\n",
    "\n",
    "    # Initialize predicted_classes if not already done\n",
    "    predicted_classes = np.array(predicted_classes)\n",
    "\n",
    "    # Add placeholder predictions (e.g., class 1) to match the expected number of rows\n",
    "    for missing_img in missing_images:\n",
    "        test_ids.append(missing_img.split('.')[0])\n",
    "        predicted_classes = np.append(predicted_classes, [1])  # Default prediction as class 1\n",
    "        \n",
    "        # Step 8: Create Submission File\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'Predictions': predicted_classes\n",
    "})\n",
    "\n",
    "# Save submission variable as a .csv file in the current working directory\n",
    "submission.to_csv('submission5.csv', index=False)\n",
    "print(\"Submission file created successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
