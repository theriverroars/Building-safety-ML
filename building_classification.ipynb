{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ_OKloLWrum",
        "outputId": "e60faf37-0336-492d-bd73-c356430f3f1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Loaded 2516 images.\n",
            "Shape of images array: (2516, 128, 128, 3)\n",
            "Shape of labels array: (2516,)\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 4s/step - accuracy: 0.2057 - loss: 2.0219 - val_accuracy: 0.0913 - val_loss: 1.7279 - learning_rate: 5.0000e-05\n",
            "Epoch 2/40\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 4s/step - accuracy: 0.2860 - loss: 1.7198 - val_accuracy: 0.1845 - val_loss: 1.6301 - learning_rate: 5.0000e-05\n",
            "Epoch 3/40\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 4s/step - accuracy: 0.2912 - loss: 1.6242 - val_accuracy: 0.0972 - val_loss: 1.6537 - learning_rate: 5.0000e-05\n",
            "Epoch 4/40\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 4s/step - accuracy: 0.3487 - loss: 1.5758 - val_accuracy: 0.1885 - val_loss: 1.6100 - learning_rate: 5.0000e-05\n",
            "Epoch 5/40\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 4s/step - accuracy: 0.3902 - loss: 1.4807 - val_accuracy: 0.1964 - val_loss: 1.7000 - learning_rate: 5.0000e-05\n",
            "Epoch 6/40\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 4s/step - accuracy: 0.3603 - loss: 1.4411 - val_accuracy: 0.1468 - val_loss: 1.7643 - learning_rate: 5.0000e-05\n",
            "Epoch 7/40\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 4s/step - accuracy: 0.4136 - loss: 1.3693 - val_accuracy: 0.1468 - val_loss: 1.7974 - learning_rate: 5.0000e-05\n",
            "Epoch 8/40\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 4s/step - accuracy: 0.4053 - loss: 1.4149 - val_accuracy: 0.1825 - val_loss: 1.7535 - learning_rate: 5.0000e-05\n",
            "Epoch 9/40\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 4s/step - accuracy: 0.4348 - loss: 1.3147 - val_accuracy: 0.2183 - val_loss: 1.6439 - learning_rate: 5.0000e-05\n",
            "Warning: Could not load image .DS_Store\n",
            "Loaded 478 images.\n",
            "Missing images: ['.DS_Store']\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 900ms/step\n",
            "Expected 479 images, but loaded 478. Adding placeholder rows for missing images.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_bcbef6c5-854e-4492-b95b-bf522192cb30\", \"submission.csv\", 2778)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# Step 1: Mount Google Drive to access data\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define directories for training and test data\n",
        "train_dir = '/content/drive/My Drive/IISC work/ML Project/Data/Train_Data'\n",
        "test_dir = '/content/drive/My Drive/IISC work/ML Project/Data/Test_Data'\n",
        "\n",
        "# Step 2: Load and Preprocess Training Data\n",
        "IMG_SIZE = (128, 128)\n",
        "ALLOWED_EXTENSIONS = {'.jpg', '.jpeg', '.png'}\n",
        "\n",
        "# Function to load training data\n",
        "def load_data(train_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'S': 5}\n",
        "\n",
        "    for folder in os.listdir(train_dir):\n",
        "        folder_path = os.path.join(train_dir, folder)\n",
        "        if os.path.isdir(folder_path) and folder in label_map:\n",
        "            for img_name in os.listdir(folder_path):\n",
        "                if not any(img_name.lower().endswith(ext) for ext in ALLOWED_EXTENSIONS):\n",
        "                    continue\n",
        "                img_path = os.path.join(folder_path, img_name)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.resize(img, IMG_SIZE)\n",
        "                    images.append(img)\n",
        "                    labels.append(label_map[folder])\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load training data\n",
        "if os.path.exists(train_dir):\n",
        "    images, labels = load_data(train_dir)\n",
        "    print(f\"Loaded {len(images)} images.\")\n",
        "    print(f\"Shape of images array: {images.shape}\")\n",
        "    print(f\"Shape of labels array: {labels.shape}\")\n",
        "\n",
        "# Step 3: Prepare Data for Training\n",
        "labels = labels - 1  # Adjust labels to be 0-based\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Advanced Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,  # Reduce rotation range\n",
        "    width_shift_range=0.2,  # Reduce shift range\n",
        "    height_shift_range=0.2,  # Reduce shift range\n",
        "    shear_range=0.2,  # Reduce shear range\n",
        "    zoom_range=0.2,  # Reduce zoom\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Step 4: Define the Model Using EfficientNetB0\n",
        "base_model = EfficientNetB0(input_shape=(128, 128, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Unfreeze fewer layers for fine-tuning\n",
        "for layer in base_model.layers[-20:]:  # Unfreeze last 20 layers for fine-tuning\n",
        "    layer.trainable = True\n",
        "\n",
        "# Define model architecture\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),  # Reduce neurons in dense layer\n",
        "    Dropout(0.3),  # Reduce dropout rate to retain more information\n",
        "    Dense(256, activation='relu'),  # Additional dense layer\n",
        "    Dropout(0.3),\n",
        "    Dense(5, activation='softmax')  # Assuming 5 classes\n",
        "])\n",
        "\n",
        "# Compile the model with AdamW optimizer\n",
        "model.compile(optimizer=AdamW(learning_rate=0.00005), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Training the Model\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00005)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Compute class weights (optional: you can experiment with and without this)\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = {i: weight for i, weight in enumerate(class_weights)}\n",
        "\n",
        "batch_size = 32  # Use a smaller batch size\n",
        "\n",
        "# Train the model with data augmentation, class weights, and callbacks\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "          validation_data=val_datagen.flow(X_val, y_val),\n",
        "          epochs=40,  # Increase epochs for better convergence\n",
        "          class_weight=class_weights,  # Experiment with and without this\n",
        "          callbacks=[reduce_lr, early_stopping])  # Add early stopping to prevent overfitting\n",
        "\n",
        "# Step 6: Load and Preprocess Test Data with Missing Image Handling\n",
        "def load_test_data(test_dir):\n",
        "    test_images = []\n",
        "    test_ids = []\n",
        "    missing_images = []\n",
        "    for img_name in os.listdir(test_dir):\n",
        "        img_path = os.path.join(test_dir, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, (128, 128))\n",
        "            test_images.append(img)\n",
        "            test_ids.append(img_name.split('.')[0])\n",
        "        else:\n",
        "            print(f\"Warning: Could not load image {img_name}\")\n",
        "            missing_images.append(img_name)\n",
        "\n",
        "    print(f\"Loaded {len(test_images)} images.\")\n",
        "    print(f\"Missing images: {missing_images}\")\n",
        "\n",
        "    return np.array(test_images), test_ids, missing_images\n",
        "\n",
        "# Load test data\n",
        "test_images, test_ids, missing_images = load_test_data(test_dir)\n",
        "\n",
        "# Normalize test data\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Step 7: Make Predictions\n",
        "predictions = model.predict(test_images)\n",
        "predicted_classes = np.argmax(predictions, axis=1) + 1  # Adjust to match original labels\n",
        "\n",
        "# Ensure predicted_classes has 479 entries\n",
        "if len(predicted_classes) < 479:\n",
        "    print(f\"Expected 479 images, but loaded {len(test_ids)}. Adding placeholder rows for missing images.\")\n",
        "\n",
        "    # Initialize predicted_classes if not already done\n",
        "    predicted_classes = np.array(predicted_classes)\n",
        "\n",
        "    # Add placeholder predictions (e.g., class 1) to match the expected number of rows\n",
        "    for missing_img in missing_images:\n",
        "        test_ids.append(missing_img.split('.')[0])\n",
        "        predicted_classes = np.append(predicted_classes, [1])  # Default prediction as class 1\n",
        "\n",
        "# Step 8: Create Submission File\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'Predictions': predicted_classes\n",
        "})\n",
        "\n",
        "# Save submission file\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "# Step 9: Download Submission File\n",
        "from google.colab import files\n",
        "files.download('submission.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "roDUz5G6i6Km",
        "outputId": "16df77c2-3587-4f90-8535-8815ef7af0e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loaded 2516 images.\n",
            "Shape of images array: (2516, 224, 224, 3)\n",
            "Shape of labels array: (2516,)\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n",
            "\u001b[1m27018416/27018416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1266s\u001b[0m 19s/step - accuracy: 0.2624 - loss: 5.3559 - val_accuracy: 0.1310 - val_loss: 4.3728 - learning_rate: 1.0000e-05\n",
            "Epoch 2/25\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1098s\u001b[0m 17s/step - accuracy: 0.2501 - loss: 4.9447 - val_accuracy: 0.1012 - val_loss: 4.5074 - learning_rate: 1.0000e-05\n",
            "Epoch 3/25\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1137s\u001b[0m 18s/step - accuracy: 0.2245 - loss: 4.8522 - val_accuracy: 0.2857 - val_loss: 4.3705 - learning_rate: 1.0000e-05\n",
            "Epoch 4/25\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1169s\u001b[0m 18s/step - accuracy: 0.2597 - loss: 4.6898 - val_accuracy: 0.2778 - val_loss: 4.3120 - learning_rate: 1.0000e-05\n",
            "Epoch 5/25\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1200s\u001b[0m 19s/step - accuracy: 0.2606 - loss: 4.6235 - val_accuracy: 0.2798 - val_loss: 4.2813 - learning_rate: 1.0000e-05\n",
            "Epoch 6/25\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1086s\u001b[0m 17s/step - accuracy: 0.2808 - loss: 4.5625 - val_accuracy: 0.2619 - val_loss: 4.2969 - learning_rate: 1.0000e-05\n",
            "Epoch 7/25\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1114s\u001b[0m 18s/step - accuracy: 0.2922 - loss: 4.5196 - val_accuracy: 0.2897 - val_loss: 4.2220 - learning_rate: 1.0000e-05\n",
            "Epoch 8/25\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1164s\u001b[0m 18s/step - accuracy: 0.2808 - loss: 4.5163 - val_accuracy: 0.2778 - val_loss: 4.2342 - learning_rate: 1.0000e-05\n",
            "Epoch 9/25\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1138s\u001b[0m 18s/step - accuracy: 0.3053 - loss: 4.4143 - val_accuracy: 0.2837 - val_loss: 4.2158 - learning_rate: 1.0000e-05\n",
            "Epoch 10/25\n",
            "\u001b[1m16/63\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:26\u001b[0m 17s/step - accuracy: 0.3142 - loss: 4.4657"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications import EfficientNetB1\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Step 1: Mount Google Drive to access data\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define directories for training and test data\n",
        "train_dir = '/content/drive/My Drive/Project 1 Data (1)/Project 1 Data/Train_Data'\n",
        "test_dir = '/content/drive/My Drive/Project 1 Data (1)/Project 1 Data/Test_Data'\n",
        "\n",
        "# Step 2: Load and Preprocess Training Data\n",
        "IMG_SIZE = (224, 224)  # Increased image size\n",
        "ALLOWED_EXTENSIONS = {'.jpg', '.jpeg', '.png'}\n",
        "\n",
        "# Function to load training data\n",
        "def load_data(train_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'S': 5}\n",
        "\n",
        "    for folder in os.listdir(train_dir):\n",
        "        folder_path = os.path.join(train_dir, folder)\n",
        "        if os.path.isdir(folder_path) and folder in label_map:\n",
        "            for img_name in os.listdir(folder_path):\n",
        "                if not any(img_name.lower().endswith(ext) for ext in ALLOWED_EXTENSIONS):\n",
        "                    continue\n",
        "                img_path = os.path.join(folder_path, img_name)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.resize(img, IMG_SIZE)\n",
        "                    images.append(img)\n",
        "                    labels.append(label_map[folder])\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load training data\n",
        "if os.path.exists(train_dir):\n",
        "    images, labels = load_data(train_dir)\n",
        "    print(f\"Loaded {len(images)} images.\")\n",
        "    print(f\"Shape of images array: {images.shape}\")\n",
        "    print(f\"Shape of labels array: {labels.shape}\")\n",
        "\n",
        "# Step 3: Prepare Data for Training\n",
        "labels = labels - 1  # Adjust labels to be 0-based\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Advanced Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255,\n",
        "    brightness_range=[0.8, 1.2],  # New augmentation for brightness\n",
        "    channel_shift_range=0.1  # New augmentation for channel shifts\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Step 4: Define the Model Using EfficientNetB1\n",
        "base_model = EfficientNetB1(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Unfreeze all layers for fine-tuning\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Define the Sequential model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(1024, activation='relu', kernel_regularizer=l2(0.001)),  # Added L2 regularization\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu', kernel_regularizer=l2(0.001)),  # Additional dense layer with L2 regularization\n",
        "    Dropout(0.5),\n",
        "    Dense(5, activation='softmax')  # Assuming 5 classes\n",
        "])\n",
        "\n",
        "# Compile the model with AdamW optimizer and a lower learning rate for fine-tuning\n",
        "model.compile(optimizer=AdamW(learning_rate=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Training the Model\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=1e-7)\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Train the model\n",
        "batch_size = 32\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "          validation_data=val_datagen.flow(X_val, y_val),\n",
        "          epochs=25,  # Increased number of epochs for better convergence\n",
        "          class_weight=class_weights_dict,\n",
        "          callbacks=[reduce_lr])\n",
        "\n",
        "# Step 6: Load and Preprocess Test Data with Missing Image Handling\n",
        "def load_test_data(test_dir):\n",
        "    test_images = []\n",
        "    test_ids = []\n",
        "    missing_images = []\n",
        "    for img_name in os.listdir(test_dir):\n",
        "        img_path = os.path.join(test_dir, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "            test_images.append(img)\n",
        "            test_ids.append(img_name.split('.')[0])\n",
        "        else:\n",
        "            print(f\"Warning: Could not load image {img_name}\")\n",
        "            missing_images.append(img_name)\n",
        "\n",
        "    print(f\"Loaded {len(test_images)} images.\")\n",
        "    print(f\"Missing images: {missing_images}\")\n",
        "\n",
        "    return np.array(test_images), test_ids, missing_images\n",
        "\n",
        "# Load test data\n",
        "test_images, test_ids, missing_images = load_test_data(test_dir)\n",
        "\n",
        "# Normalize test data\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Step 7: Make Predictions\n",
        "predictions = model.predict(test_images)\n",
        "predicted_classes = np.argmax(predictions, axis=1) + 1  # Adjust to match original labels\n",
        "\n",
        "# Ensure predicted_classes has 479 entries\n",
        "if len(predicted_classes) < 479:\n",
        "    print(f\"Expected 479 images, but loaded {len(test_ids)}. Adding placeholder rows for missing images.\")\n",
        "\n",
        "    # Initialize predicted_classes if not already done\n",
        "    predicted_classes = np.array(predicted_classes)\n",
        "\n",
        "    # Add placeholder predictions (e.g., class 1) to match the expected number of rows\n",
        "    for missing_img in missing_images:\n",
        "        test_ids.append(missing_img.split('.')[0])\n",
        "        predicted_classes = np.append(predicted_classes, [1])  # Default prediction as class 1\n",
        "\n",
        "# Step 8: Create Submission File\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'Predictions': predicted_classes\n",
        "})\n",
        "\n",
        "# Save submission file\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "# Step 9: Download Submission File\n",
        "from google.colab import files\n",
        "files.download('submission.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyeTYQBojdvV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}