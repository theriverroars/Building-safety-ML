{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdamW\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m class_weight\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReduceLROnPlateau, EarlyStopping\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "#import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ_OKloLWrum",
        "outputId": "e60faf37-0336-492d-bd73-c356430f3f1e"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[1;32m--> 988\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# Step 1: Mount Google Drive to access data\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define directories for training and test data\n",
        "train_dir = '/content/drive/My Drive/IISC work/ML Project/Data/Train_Data'\n",
        "test_dir = '/content/drive/My Drive/IISC work/ML Project/Data/Test_Data'\n",
        "\n",
        "# Step 2: Load and Preprocess Training Data\n",
        "IMG_SIZE = (128, 128)\n",
        "ALLOWED_EXTENSIONS = {'.jpg', '.jpeg', '.png'}\n",
        "\n",
        "# Function to load training data\n",
        "def load_data(train_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'S': 5}\n",
        "\n",
        "    for folder in os.listdir(train_dir):\n",
        "        folder_path = os.path.join(train_dir, folder)\n",
        "        if os.path.isdir(folder_path) and folder in label_map:\n",
        "            for img_name in os.listdir(folder_path):\n",
        "                if not any(img_name.lower().endswith(ext) for ext in ALLOWED_EXTENSIONS):\n",
        "                    continue\n",
        "                img_path = os.path.join(folder_path, img_name)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.resize(img, IMG_SIZE)\n",
        "                    images.append(img)\n",
        "                    labels.append(label_map[folder])\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load training data\n",
        "if os.path.exists(train_dir):\n",
        "    images, labels = load_data(train_dir)\n",
        "    print(f\"Loaded {len(images)} images.\")\n",
        "    print(f\"Shape of images array: {images.shape}\")\n",
        "    print(f\"Shape of labels array: {labels.shape}\")\n",
        "\n",
        "# Step 3: Prepare Data for Training\n",
        "labels = labels - 1  # Adjust labels to be 0-based\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Advanced Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,  # Reduce rotation range\n",
        "    width_shift_range=0.2,  # Reduce shift range\n",
        "    height_shift_range=0.2,  # Reduce shift range\n",
        "    shear_range=0.2,  # Reduce shear range\n",
        "    zoom_range=0.2,  # Reduce zoom\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Step 4: Define the Model Using EfficientNetB0\n",
        "base_model = EfficientNetB0(input_shape=(128, 128, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Unfreeze fewer layers for fine-tuning\n",
        "for layer in base_model.layers[-20:]:  # Unfreeze last 20 layers for fine-tuning\n",
        "    layer.trainable = True\n",
        "\n",
        "# Define model architecture\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),  # Reduce neurons in dense layer\n",
        "    Dropout(0.3),  # Reduce dropout rate to retain more information\n",
        "    Dense(256, activation='relu'),  # Additional dense layer\n",
        "    Dropout(0.3),\n",
        "    Dense(5, activation='softmax')  # Assuming 5 classes\n",
        "])\n",
        "\n",
        "# Compile the model with AdamW optimizer\n",
        "model.compile(optimizer=AdamW(learning_rate=0.00005), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Training the Model\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00005)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Compute class weights (optional: you can experiment with and without this)\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = {i: weight for i, weight in enumerate(class_weights)}\n",
        "\n",
        "batch_size = 32  # Use a smaller batch size\n",
        "\n",
        "# Train the model with data augmentation, class weights, and callbacks\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "          validation_data=val_datagen.flow(X_val, y_val),\n",
        "          epochs=40,  # Increase epochs for better convergence\n",
        "          class_weight=class_weights,  # Experiment with and without this\n",
        "          callbacks=[reduce_lr, early_stopping])  # Add early stopping to prevent overfitting\n",
        "\n",
        "# Step 6: Load and Preprocess Test Data with Missing Image Handling\n",
        "def load_test_data(test_dir):\n",
        "    test_images = []\n",
        "    test_ids = []\n",
        "    missing_images = []\n",
        "    for img_name in os.listdir(test_dir):\n",
        "        img_path = os.path.join(test_dir, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, (128, 128))\n",
        "            test_images.append(img)\n",
        "            test_ids.append(img_name.split('.')[0])\n",
        "        else:\n",
        "            print(f\"Warning: Could not load image {img_name}\")\n",
        "            missing_images.append(img_name)\n",
        "\n",
        "    print(f\"Loaded {len(test_images)} images.\")\n",
        "    print(f\"Missing images: {missing_images}\")\n",
        "\n",
        "    return np.array(test_images), test_ids, missing_images\n",
        "\n",
        "# Load test data\n",
        "test_images, test_ids, missing_images = load_test_data(test_dir)\n",
        "\n",
        "# Normalize test data\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Step 7: Make Predictions\n",
        "predictions = model.predict(test_images)\n",
        "predicted_classes = np.argmax(predictions, axis=1) + 1  # Adjust to match original labels\n",
        "\n",
        "# Ensure predicted_classes has 479 entries\n",
        "if len(predicted_classes) < 479:\n",
        "    print(f\"Expected 479 images, but loaded {len(test_ids)}. Adding placeholder rows for missing images.\")\n",
        "\n",
        "    # Initialize predicted_classes if not already done\n",
        "    predicted_classes = np.array(predicted_classes)\n",
        "\n",
        "    # Add placeholder predictions (e.g., class 1) to match the expected number of rows\n",
        "    for missing_img in missing_images:\n",
        "        test_ids.append(missing_img.split('.')[0])\n",
        "        predicted_classes = np.append(predicted_classes, [1])  # Default prediction as class 1\n",
        "\n",
        "# Step 8: Create Submission File\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'Predictions': predicted_classes\n",
        "})\n",
        "\n",
        "# Save submission file\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "# Step 9: Download Submission File\n",
        "from google.colab import files\n",
        "files.download('submission.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "roDUz5G6i6Km",
        "outputId": "16df77c2-3587-4f90-8535-8815ef7af0e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loaded 2516 images.\n",
            "Shape of images array: (2516, 224, 224, 3)\n",
            "Shape of labels array: (2516,)\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n",
            "\u001b[1m27018416/27018416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1266s\u001b[0m 19s/step - accuracy: 0.2624 - loss: 5.3559 - val_accuracy: 0.1310 - val_loss: 4.3728 - learning_rate: 1.0000e-05\n",
            "Epoch 2/25\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1098s\u001b[0m 17s/step - accuracy: 0.2501 - loss: 4.9447 - val_accuracy: 0.1012 - val_loss: 4.5074 - learning_rate: 1.0000e-05\n",
            "Epoch 3/25\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1137s\u001b[0m 18s/step - accuracy: 0.2245 - loss: 4.8522 - val_accuracy: 0.2857 - val_loss: 4.3705 - learning_rate: 1.0000e-05\n",
            "Epoch 4/25\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1169s\u001b[0m 18s/step - accuracy: 0.2597 - loss: 4.6898 - val_accuracy: 0.2778 - val_loss: 4.3120 - learning_rate: 1.0000e-05\n",
            "Epoch 5/25\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1200s\u001b[0m 19s/step - accuracy: 0.2606 - loss: 4.6235 - val_accuracy: 0.2798 - val_loss: 4.2813 - learning_rate: 1.0000e-05\n",
            "Epoch 6/25\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1086s\u001b[0m 17s/step - accuracy: 0.2808 - loss: 4.5625 - val_accuracy: 0.2619 - val_loss: 4.2969 - learning_rate: 1.0000e-05\n",
            "Epoch 7/25\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1114s\u001b[0m 18s/step - accuracy: 0.2922 - loss: 4.5196 - val_accuracy: 0.2897 - val_loss: 4.2220 - learning_rate: 1.0000e-05\n",
            "Epoch 8/25\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1164s\u001b[0m 18s/step - accuracy: 0.2808 - loss: 4.5163 - val_accuracy: 0.2778 - val_loss: 4.2342 - learning_rate: 1.0000e-05\n",
            "Epoch 9/25\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1138s\u001b[0m 18s/step - accuracy: 0.3053 - loss: 4.4143 - val_accuracy: 0.2837 - val_loss: 4.2158 - learning_rate: 1.0000e-05\n",
            "Epoch 10/25\n",
            "\u001b[1m16/63\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:26\u001b[0m 17s/step - accuracy: 0.3142 - loss: 4.4657"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications import EfficientNetB1\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Step 1: Mount Google Drive to access data\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define directories for training and test data\n",
        "train_dir = '/content/drive/My Drive/Project 1 Data (1)/Project 1 Data/Train_Data'\n",
        "test_dir = '/content/drive/My Drive/Project 1 Data (1)/Project 1 Data/Test_Data'\n",
        "\n",
        "# Step 2: Load and Preprocess Training Data\n",
        "IMG_SIZE = (224, 224)  # Increased image size\n",
        "ALLOWED_EXTENSIONS = {'.jpg', '.jpeg', '.png'}\n",
        "\n",
        "# Function to load training data\n",
        "def load_data(train_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'S': 5}\n",
        "\n",
        "    for folder in os.listdir(train_dir):\n",
        "        folder_path = os.path.join(train_dir, folder)\n",
        "        if os.path.isdir(folder_path) and folder in label_map:\n",
        "            for img_name in os.listdir(folder_path):\n",
        "                if not any(img_name.lower().endswith(ext) for ext in ALLOWED_EXTENSIONS):\n",
        "                    continue\n",
        "                img_path = os.path.join(folder_path, img_name)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.resize(img, IMG_SIZE)\n",
        "                    images.append(img)\n",
        "                    labels.append(label_map[folder])\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load training data\n",
        "if os.path.exists(train_dir):\n",
        "    images, labels = load_data(train_dir)\n",
        "    print(f\"Loaded {len(images)} images.\")\n",
        "    print(f\"Shape of images array: {images.shape}\")\n",
        "    print(f\"Shape of labels array: {labels.shape}\")\n",
        "\n",
        "# Step 3: Prepare Data for Training\n",
        "labels = labels - 1  # Adjust labels to be 0-based\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Advanced Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255,\n",
        "    brightness_range=[0.8, 1.2],  # New augmentation for brightness\n",
        "    channel_shift_range=0.1  # New augmentation for channel shifts\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Step 4: Define the Model Using EfficientNetB1\n",
        "base_model = EfficientNetB1(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Unfreeze all layers for fine-tuning\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Define the Sequential model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(1024, activation='relu', kernel_regularizer=l2(0.001)),  # Added L2 regularization\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu', kernel_regularizer=l2(0.001)),  # Additional dense layer with L2 regularization\n",
        "    Dropout(0.5),\n",
        "    Dense(5, activation='softmax')  # Assuming 5 classes\n",
        "])\n",
        "\n",
        "# Compile the model with AdamW optimizer and a lower learning rate for fine-tuning\n",
        "model.compile(optimizer=AdamW(learning_rate=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Training the Model\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=1e-7)\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Train the model\n",
        "batch_size = 32\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "          validation_data=val_datagen.flow(X_val, y_val),\n",
        "          epochs=25,  # Increased number of epochs for better convergence\n",
        "          class_weight=class_weights_dict,\n",
        "          callbacks=[reduce_lr])\n",
        "\n",
        "# Step 6: Load and Preprocess Test Data with Missing Image Handling\n",
        "def load_test_data(test_dir):\n",
        "    test_images = []\n",
        "    test_ids = []\n",
        "    missing_images = []\n",
        "    for img_name in os.listdir(test_dir):\n",
        "        img_path = os.path.join(test_dir, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, IMG_SIZE)\n",
        "            test_images.append(img)\n",
        "            test_ids.append(img_name.split('.')[0])\n",
        "        else:\n",
        "            print(f\"Warning: Could not load image {img_name}\")\n",
        "            missing_images.append(img_name)\n",
        "\n",
        "    print(f\"Loaded {len(test_images)} images.\")\n",
        "    print(f\"Missing images: {missing_images}\")\n",
        "\n",
        "    return np.array(test_images), test_ids, missing_images\n",
        "\n",
        "# Load test data\n",
        "test_images, test_ids, missing_images = load_test_data(test_dir)\n",
        "\n",
        "# Normalize test data\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Step 7: Make Predictions\n",
        "predictions = model.predict(test_images)\n",
        "predicted_classes = np.argmax(predictions, axis=1) + 1  # Adjust to match original labels\n",
        "\n",
        "# Ensure predicted_classes has 479 entries\n",
        "if len(predicted_classes) < 479:\n",
        "    print(f\"Expected 479 images, but loaded {len(test_ids)}. Adding placeholder rows for missing images.\")\n",
        "\n",
        "    # Initialize predicted_classes if not already done\n",
        "    predicted_classes = np.array(predicted_classes)\n",
        "\n",
        "    # Add placeholder predictions (e.g., class 1) to match the expected number of rows\n",
        "    for missing_img in missing_images:\n",
        "        test_ids.append(missing_img.split('.')[0])\n",
        "        predicted_classes = np.append(predicted_classes, [1])  # Default prediction as class 1\n",
        "\n",
        "# Step 8: Create Submission File\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'Predictions': predicted_classes\n",
        "})\n",
        "\n",
        "# Save submission file\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "# Step 9: Download Submission File\n",
        "from google.colab import files\n",
        "files.download('submission.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyeTYQBojdvV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
